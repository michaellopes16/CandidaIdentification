{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9f2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sktime==0.14.0 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy<1.23,>=1.21.0 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from sktime==0.14.0) (1.21.6)\n",
      "Requirement already satisfied: pandas<1.6.0,>=1.1.0 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from sktime==0.14.0) (1.5.1)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from sktime==0.14.0) (1.2.13)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from sktime==0.14.0) (0.13.5)\n",
      "Requirement already satisfied: scipy<2.0.0 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from sktime==0.14.0) (1.8.1)\n",
      "Requirement already satisfied: numba>=0.53 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from sktime==0.14.0) (0.56.4)\n",
      "Requirement already satisfied: scikit-learn<1.2.0,>=0.24.0 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from sktime==0.14.0) (1.0.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from deprecated>=1.2.13->sktime==0.14.0) (1.14.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from numba>=0.53->sktime==0.14.0) (0.39.1)\n",
      "Requirement already satisfied: setuptools in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from numba>=0.53->sktime==0.14.0) (65.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from pandas<1.6.0,>=1.1.0->sktime==0.14.0) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from pandas<1.6.0,>=1.1.0->sktime==0.14.0) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from scikit-learn<1.2.0,>=0.24.0->sktime==0.14.0) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from scikit-learn<1.2.0,>=0.24.0->sktime==0.14.0) (1.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from statsmodels>=0.12.1->sktime==0.14.0) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from statsmodels>=0.12.1->sktime==0.14.0) (0.5.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.12.1->sktime==0.14.0) (3.0.9)\n",
      "Requirement already satisfied: six in d:\\programs\\envs\\runmodelsenv\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.12.1->sktime==0.14.0) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# #Requeriments\n",
    "# %pip install numpy==1.22\n",
    "# %pip install pandas==1.5.0\n",
    "# %pip install numpy scipy joblib scikit-learn --force-reinstall\n",
    "%pip install sktime==0.14.0\n",
    "# %pip install tensorflow\n",
    "# %pip install tensorflow-estimator==2.5\n",
    "# %pip install tensorflow-gpu==2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3022fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import tensorflow as tf\n",
    "from pickle import dump\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "#Import Models\n",
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "from sktime.classification.hybrid import HIVECOTEV1\n",
    "from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "from sktime.classification.interval_based import RandomIntervalSpectralEnsemble\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "# from sktime._contrib.vector_classifiers._rotation_forest import RotationForest\n",
    "from sktime.classification.kernel_based._rocket_classifier import RocketClassifier\n",
    "\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "\n",
    "# from sktime.datasets import load_from_arff_to_dataframe as load_arff\n",
    "#numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e535777c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\envs\\RunModelsEnv\\lib\\site-packages\\pandas\\__init__.py\n",
      "['ArrowDtype', 'BooleanDtype', 'Categorical', 'CategoricalDtype', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'DatetimeTZDtype', 'ExcelFile', 'ExcelWriter', 'Flags', 'Float32Dtype', 'Float64Dtype', 'Float64Index', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int16Dtype', 'Int32Dtype', 'Int64Dtype', 'Int64Index', 'Int8Dtype', 'Interval', 'IntervalDtype', 'IntervalIndex', 'MultiIndex', 'NA', 'NaT', 'NamedAgg', 'Period', 'PeriodDtype', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseDtype', 'StringDtype', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'UInt16Dtype', 'UInt32Dtype', 'UInt64Dtype', 'UInt64Index', 'UInt8Dtype', '__all__', '__builtins__', '__cached__', '__deprecated_num_index_names', '__dir__', '__doc__', '__docformat__', '__file__', '__getattr__', '__git_version__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_config', '_is_numpy_dev', '_libs', '_testing', '_typing', '_version', 'annotations', 'api', 'array', 'arrays', 'bdate_range', 'compat', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'describe_option', 'errors', 'eval', 'factorize', 'from_dummies', 'get_dummies', 'get_option', 'infer_freq', 'interval_range', 'io', 'isna', 'isnull', 'json_normalize', 'lreshape', 'melt', 'merge', 'merge_asof', 'merge_ordered', 'notna', 'notnull', 'offsets', 'option_context', 'options', 'pandas', 'period_range', 'pivot', 'pivot_table', 'plotting', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_orc', 'read_parquet', 'read_pickle', 'read_sas', 'read_spss', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'read_xml', 'reset_option', 'set_eng_float_format', 'set_option', 'show_versions', 'test', 'testing', 'timedelta_range', 'to_datetime', 'to_numeric', 'to_pickle', 'to_timedelta', 'tseries', 'unique', 'util', 'value_counts', 'wide_to_long']\n"
     ]
    }
   ],
   "source": [
    "print(pd.__file__)\n",
    "print(dir(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d5e773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The installed version of TensorFlow does not include GPU support.\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "else:\n",
    "    print(\"The installed version of TensorFlow does not include GPU support.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54219d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mlb\\AppData\\Local\\Temp\\ipykernel_22332\\565982385.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2afe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870b1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d5dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58bb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5b5e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   print(\n",
    "#       '\\n\\nThis error most likely means that this notebook is not '\n",
    "#       'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "#       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "#   raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dab6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt_metrics():\n",
    "    columns = ['TimeSeriesForestClassifier','HIVECOTE1','HIVECOTE2','RISE','BOSSEnsemble','ROCKET'\n",
    "               ,'KNeighborsTimeSeriesClassifier','ShapeletTransformClassifier']\n",
    "    df_precision = pd.DataFrame(data= None,\n",
    "                           columns=columns)\n",
    "    df_accuracy  = pd.DataFrame(data= None,\n",
    "                           columns=columns)\n",
    "    df_f1        = pd.DataFrame(data= None,\n",
    "                           columns=columns)\n",
    "    df_recall    = pd.DataFrame(data= None,\n",
    "                           columns=columns)\n",
    "    df_std       = pd.DataFrame(data= None,\n",
    "                           columns=columns)\n",
    "    return df_precision, df_accuracy, df_f1, df_recall, df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "789facf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_df_metrics(precision, accuracy, f1, recall):\n",
    "    print(f\"Precision in populate_df_metrics: {precision}\")\n",
    "    df_precision = df_precision.append(precision, ignore_index=True)\n",
    "    print(f\"Df precision after append: {df_precision}\")\n",
    "    df_accuracy.append(pd.DataFrame(accuracy))\n",
    "    df_f1.append(pd.DataFrame(f1))\n",
    "    df_recall.append(pd.DataFrame(recall))\n",
    "  \n",
    "def save_std(df_accuracy,df_std):\n",
    "    for row in df_accuracy:\n",
    "        df_std[row] = np.std(df_accuracy[row])\n",
    "        print(f\"STD COL: {df_std[row]}\")\n",
    "    print(f\"STD antes do %save: {df_std}\")\n",
    "    df_std.to_csv(\"results4/\" + 'df_all_std.csv', index=False)\n",
    "    print(f\"Save STD: {df_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e9d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def create_models(models):\n",
    "#       n_estimators=200, n_estimators=6, n_estimators=400   \n",
    "    models.append(('TimeSeriesForestClassifier',TimeSeriesForestClassifier()))\n",
    "# #   n_estimators=3, n_estimators=200, n_estimators=400    \n",
    "    models.append(('HIVECOTE1', HIVECOTEV1(random_state=2)))\n",
    "    \n",
    "#   n_estimators=3, n_estimators=200, n_estimators=400    \n",
    "    models.append(('HIVECOTE2',HIVECOTEV2(time_limit_in_minutes=0.2)))\n",
    "#   n_estimators=50, n_estimators=3, n_estimators=100 \n",
    "    models.append(('RISE',RandomIntervalSpectralEnsemble()))\n",
    "#   max_ensemble_size=50, max_ensemble_size=3, max_ensemble_size=100\n",
    "#   DICA: Geralmente, o max_win_len_prop é o dobro do min_window\n",
    "    models.append(('BOSSEnsemble',BOSSEnsemble(max_ensemble_size=3, min_window =9, max_win_len_prop=18)))\n",
    "#   num_kernels=10000, num_kernels=5000, num_kernels=20000 \n",
    "    models.append(('ROCKET', RocketClassifier()))\n",
    "    #     #   n_neighbors=1, n_neighbors=5, n_neighbors=10\n",
    "    models.append(('KNeighborsTimeSeriesClassifier',KNeighborsTimeSeriesClassifier()))\n",
    "    #     n_estimators=200, n_estimators=6, n_estimators=400     \n",
    "    models.append(('ShapeletTransformClassifier',ShapeletTransformClassifier(\n",
    "        n_shapelet_samples=500,\n",
    "        max_shapelets=20,\n",
    "        batch_size=100,\n",
    "    )))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c93c04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_pipeline(StandardScaler(with_mean=False),RocketClassifier())\n",
    "# model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfdb2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save metrics\n",
    "def save_results(df_to_save, name, model, train_val_test):\n",
    "    #save the model\n",
    "    print(\"Saving model...\")\n",
    "    dump(model, open('results5/'+name+'_'+train_val_test+'_model2.pkl', 'wb'))\n",
    "    print(\"Saving metrics...\")\n",
    "    print(f\"Df accuracy: {df_to_save}\")\n",
    "    df_to_save.to_csv(\"results5/\" + 'df_'+name+'_'+train_val_test+'2.csv', index=False)\n",
    "    print(\"Accuracy of models:\")\n",
    "    print(df_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93b6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U setuptools pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa7eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install cuda-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38327f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install cupy-cuda11x -f https://pip.cupy.dev/aarch64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49689259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -c numba -c conda-forge -c defaults cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27066fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37f0c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import jit, cuda, vectorize, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42cdef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2071290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = r\"C:\\Users\\mlb\\TSC_Data\\newDataSet\"\n",
    "testeDataFrame = \"\\AllCandida_TEST.csv\"\n",
    "trainDataFrame = \"\\AllCandida_TRAIN.csv\"\n",
    "valDataFrame = \"\\AllCandida_VAL.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f779a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "from sktime.datatypes._panel._convert import (\n",
    "    from_2d_array_to_nested,\n",
    "    from_nested_to_2d_array,\n",
    ")\n",
    "from sktime.datatypes._panel._check import is_nested_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83803f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino 238\n",
      "Teste 80\n",
      "X_val_1 79\n"
     ]
    }
   ],
   "source": [
    "candida_data_train  = pd.read_csv(rootPath+trainDataFrame, sep=\",\")\n",
    "# 652 is the column of label\n",
    "y_train = candida_data_train['652']\n",
    "X_train_1 = candida_data_train.drop(columns=['652'])\n",
    "\n",
    "candida_data_test  = pd.read_csv(rootPath+testeDataFrame, sep=\",\")\n",
    "y_test = candida_data_test['652']\n",
    "X_test_1 = candida_data_test.drop(columns=['652'])\n",
    "\n",
    "bacteria_data_val  = pd.read_csv(rootPath+valDataFrame, sep=\",\")\n",
    "y_val = bacteria_data_val['652']\n",
    "X_val_1 = bacteria_data_val.drop(columns=['652'])\n",
    "\n",
    "print(f\"Treino {len(X_train_1)}\")\n",
    "print(f\"Teste {len(X_test_1)}\")\n",
    "print(f\"X_val_1 {len(X_val_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2c83be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>642</th>\n",
       "      <th>643</th>\n",
       "      <th>644</th>\n",
       "      <th>645</th>\n",
       "      <th>646</th>\n",
       "      <th>647</th>\n",
       "      <th>648</th>\n",
       "      <th>649</th>\n",
       "      <th>650</th>\n",
       "      <th>651</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097089</td>\n",
       "      <td>0.888026</td>\n",
       "      <td>0.409823</td>\n",
       "      <td>0.211322</td>\n",
       "      <td>0.011470</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.094389</td>\n",
       "      <td>0.097508</td>\n",
       "      <td>0.888311</td>\n",
       "      <td>0.412353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.211099</td>\n",
       "      <td>0.165937</td>\n",
       "      <td>0.755979</td>\n",
       "      <td>0.942633</td>\n",
       "      <td>0.147668</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.211215</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.834456</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.038346</td>\n",
       "      <td>0.578831</td>\n",
       "      <td>0.709699</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.976286</td>\n",
       "      <td>0.836283</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.037597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299426</td>\n",
       "      <td>0.882699</td>\n",
       "      <td>0.605010</td>\n",
       "      <td>0.087055</td>\n",
       "      <td>0.354621</td>\n",
       "      <td>0.506213</td>\n",
       "      <td>0.470051</td>\n",
       "      <td>0.301036</td>\n",
       "      <td>0.879555</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846607</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.637470</td>\n",
       "      <td>0.852780</td>\n",
       "      <td>0.833073</td>\n",
       "      <td>0.995040</td>\n",
       "      <td>0.842061</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542005</td>\n",
       "      <td>0.998041</td>\n",
       "      <td>0.671954</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0.561678</td>\n",
       "      <td>0.766249</td>\n",
       "      <td>0.546414</td>\n",
       "      <td>0.997163</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.824803</td>\n",
       "      <td>0.370739</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.018003</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.090825</td>\n",
       "      <td>0.033225</td>\n",
       "      <td>0.825896</td>\n",
       "      <td>0.373669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015825</td>\n",
       "      <td>0.224374</td>\n",
       "      <td>0.069241</td>\n",
       "      <td>0.649428</td>\n",
       "      <td>0.853630</td>\n",
       "      <td>0.041059</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.224307</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137392</td>\n",
       "      <td>0.833933</td>\n",
       "      <td>0.523603</td>\n",
       "      <td>0.256131</td>\n",
       "      <td>0.024064</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.158710</td>\n",
       "      <td>0.138076</td>\n",
       "      <td>0.834368</td>\n",
       "      <td>0.526231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>0.304897</td>\n",
       "      <td>0.203347</td>\n",
       "      <td>0.689033</td>\n",
       "      <td>0.955287</td>\n",
       "      <td>0.184945</td>\n",
       "      <td>0.041651</td>\n",
       "      <td>0.017419</td>\n",
       "      <td>0.305259</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.053176</td>\n",
       "      <td>0.819635</td>\n",
       "      <td>0.450645</td>\n",
       "      <td>0.101789</td>\n",
       "      <td>0.017146</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.123063</td>\n",
       "      <td>0.053329</td>\n",
       "      <td>0.820363</td>\n",
       "      <td>0.453210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013421</td>\n",
       "      <td>0.266376</td>\n",
       "      <td>0.093962</td>\n",
       "      <td>0.658882</td>\n",
       "      <td>0.940946</td>\n",
       "      <td>0.085359</td>\n",
       "      <td>0.033602</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.266856</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.724615</td>\n",
       "      <td>0.151579</td>\n",
       "      <td>0.552265</td>\n",
       "      <td>0.878849</td>\n",
       "      <td>0.306767</td>\n",
       "      <td>0.195811</td>\n",
       "      <td>0.787973</td>\n",
       "      <td>0.731672</td>\n",
       "      <td>0.149882</td>\n",
       "      <td>0.547964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463643</td>\n",
       "      <td>0.984766</td>\n",
       "      <td>0.853424</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.105496</td>\n",
       "      <td>0.873582</td>\n",
       "      <td>0.580337</td>\n",
       "      <td>0.467981</td>\n",
       "      <td>0.985817</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.170837</td>\n",
       "      <td>0.682854</td>\n",
       "      <td>0.685152</td>\n",
       "      <td>0.276231</td>\n",
       "      <td>0.052296</td>\n",
       "      <td>0.022295</td>\n",
       "      <td>0.293707</td>\n",
       "      <td>0.172024</td>\n",
       "      <td>0.683777</td>\n",
       "      <td>0.688790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049636</td>\n",
       "      <td>0.505114</td>\n",
       "      <td>0.248195</td>\n",
       "      <td>0.493305</td>\n",
       "      <td>0.915215</td>\n",
       "      <td>0.206555</td>\n",
       "      <td>0.097539</td>\n",
       "      <td>0.050178</td>\n",
       "      <td>0.506437</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.247714</td>\n",
       "      <td>0.663216</td>\n",
       "      <td>0.725540</td>\n",
       "      <td>0.340955</td>\n",
       "      <td>0.061548</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>0.248706</td>\n",
       "      <td>0.663376</td>\n",
       "      <td>0.728344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050355</td>\n",
       "      <td>0.505332</td>\n",
       "      <td>0.288121</td>\n",
       "      <td>0.530100</td>\n",
       "      <td>0.909309</td>\n",
       "      <td>0.253377</td>\n",
       "      <td>0.090435</td>\n",
       "      <td>0.051028</td>\n",
       "      <td>0.507310</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.673845</td>\n",
       "      <td>0.192923</td>\n",
       "      <td>0.654753</td>\n",
       "      <td>0.688733</td>\n",
       "      <td>0.250894</td>\n",
       "      <td>0.123837</td>\n",
       "      <td>0.661965</td>\n",
       "      <td>0.709281</td>\n",
       "      <td>0.203306</td>\n",
       "      <td>0.636198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309105</td>\n",
       "      <td>0.806746</td>\n",
       "      <td>0.920149</td>\n",
       "      <td>0.098605</td>\n",
       "      <td>0.281647</td>\n",
       "      <td>0.727355</td>\n",
       "      <td>0.485233</td>\n",
       "      <td>0.312376</td>\n",
       "      <td>0.807331</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.097089  0.888026  0.409823  0.211322  0.011470  0.002984  0.094389   \n",
       "1    0.834456  0.001447  0.038346  0.578831  0.709699  0.613095  0.976286   \n",
       "2    0.846607  0.001447  0.001259  0.637470  0.852780  0.833073  0.995040   \n",
       "3    0.032964  0.824803  0.370739  0.066015  0.018003  0.005947  0.090825   \n",
       "4    0.137392  0.833933  0.523603  0.256131  0.024064  0.007370  0.158710   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "233  0.053176  0.819635  0.450645  0.101789  0.017146  0.006038  0.123063   \n",
       "234  0.724615  0.151579  0.552265  0.878849  0.306767  0.195811  0.787973   \n",
       "235  0.170837  0.682854  0.685152  0.276231  0.052296  0.022295  0.293707   \n",
       "236  0.247714  0.663216  0.725540  0.340955  0.061548  0.027736  0.336175   \n",
       "237  0.673845  0.192923  0.654753  0.688733  0.250894  0.123837  0.661965   \n",
       "\n",
       "          7         8         9    ...       642       643       644  \\\n",
       "0    0.097508  0.888311  0.412353  ...  0.006147  0.211099  0.165937   \n",
       "1    0.836283  0.001452  0.037597  ...  0.299426  0.882699  0.605010   \n",
       "2    0.842061  0.001452  0.001000  ...  0.542005  0.998041  0.671954   \n",
       "3    0.033225  0.825896  0.373669  ...  0.015825  0.224374  0.069241   \n",
       "4    0.138076  0.834368  0.526231  ...  0.017293  0.304897  0.203347   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "233  0.053329  0.820363  0.453210  ...  0.013421  0.266376  0.093962   \n",
       "234  0.731672  0.149882  0.547964  ...  0.463643  0.984766  0.853424   \n",
       "235  0.172024  0.683777  0.688790  ...  0.049636  0.505114  0.248195   \n",
       "236  0.248706  0.663376  0.728344  ...  0.050355  0.505332  0.288121   \n",
       "237  0.709281  0.203306  0.636198  ...  0.309105  0.806746  0.920149   \n",
       "\n",
       "          645       646       647       648       649       650  651  \n",
       "0    0.755979  0.942633  0.147668  0.017130  0.006142  0.211215  0.6  \n",
       "1    0.087055  0.354621  0.506213  0.470051  0.301036  0.879555  0.6  \n",
       "2    0.088129  0.046484  0.561678  0.766249  0.546414  0.997163  1.0  \n",
       "3    0.649428  0.853630  0.041059  0.037784  0.016002  0.224307  0.8  \n",
       "4    0.689033  0.955287  0.184945  0.041651  0.017419  0.305259  0.6  \n",
       "..        ...       ...       ...       ...       ...       ...  ...  \n",
       "233  0.658882  0.940946  0.085359  0.033602  0.013576  0.266856  0.8  \n",
       "234  0.089202  0.105496  0.873582  0.580337  0.467981  0.985817  0.6  \n",
       "235  0.493305  0.915215  0.206555  0.097539  0.050178  0.506437  0.6  \n",
       "236  0.530100  0.909309  0.253377  0.090435  0.051028  0.507310  0.8  \n",
       "237  0.098605  0.281647  0.727355  0.485233  0.312376  0.807331  0.2  \n",
       "\n",
       "[238 rows x 652 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train_1))\n",
    "X_train_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b79f066b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>642</th>\n",
       "      <th>643</th>\n",
       "      <th>644</th>\n",
       "      <th>645</th>\n",
       "      <th>646</th>\n",
       "      <th>647</th>\n",
       "      <th>648</th>\n",
       "      <th>649</th>\n",
       "      <th>650</th>\n",
       "      <th>651</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029108</td>\n",
       "      <td>0.813493</td>\n",
       "      <td>0.475749</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.086889</td>\n",
       "      <td>0.029660</td>\n",
       "      <td>0.813884</td>\n",
       "      <td>0.478888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018380</td>\n",
       "      <td>0.136913</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.776878</td>\n",
       "      <td>0.857653</td>\n",
       "      <td>0.029664</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>0.137193</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034635</td>\n",
       "      <td>0.818138</td>\n",
       "      <td>0.496219</td>\n",
       "      <td>0.055261</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.035298</td>\n",
       "      <td>0.818719</td>\n",
       "      <td>0.498778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018099</td>\n",
       "      <td>0.136430</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>0.801356</td>\n",
       "      <td>0.859352</td>\n",
       "      <td>0.042351</td>\n",
       "      <td>0.038282</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>0.136463</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155122</td>\n",
       "      <td>0.697011</td>\n",
       "      <td>0.861830</td>\n",
       "      <td>0.226911</td>\n",
       "      <td>0.050652</td>\n",
       "      <td>0.020759</td>\n",
       "      <td>0.269356</td>\n",
       "      <td>0.155534</td>\n",
       "      <td>0.697346</td>\n",
       "      <td>0.862477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055422</td>\n",
       "      <td>0.422351</td>\n",
       "      <td>0.180275</td>\n",
       "      <td>0.621226</td>\n",
       "      <td>0.930314</td>\n",
       "      <td>0.185821</td>\n",
       "      <td>0.096918</td>\n",
       "      <td>0.055665</td>\n",
       "      <td>0.419849</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073446</td>\n",
       "      <td>0.839473</td>\n",
       "      <td>0.677034</td>\n",
       "      <td>0.252271</td>\n",
       "      <td>0.021784</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.157952</td>\n",
       "      <td>0.073906</td>\n",
       "      <td>0.840300</td>\n",
       "      <td>0.680059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>0.270924</td>\n",
       "      <td>0.084026</td>\n",
       "      <td>0.824578</td>\n",
       "      <td>0.992351</td>\n",
       "      <td>0.190485</td>\n",
       "      <td>0.044535</td>\n",
       "      <td>0.023046</td>\n",
       "      <td>0.269764</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.834316</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.359754</td>\n",
       "      <td>0.445307</td>\n",
       "      <td>0.628219</td>\n",
       "      <td>0.478822</td>\n",
       "      <td>0.962452</td>\n",
       "      <td>0.840422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237660</td>\n",
       "      <td>0.769956</td>\n",
       "      <td>0.511156</td>\n",
       "      <td>0.159386</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>0.368470</td>\n",
       "      <td>0.354623</td>\n",
       "      <td>0.237300</td>\n",
       "      <td>0.768426</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.915623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.461014</td>\n",
       "      <td>0.962853</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.998604</td>\n",
       "      <td>0.905503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>0.965409</td>\n",
       "      <td>0.647164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123608</td>\n",
       "      <td>0.376493</td>\n",
       "      <td>0.683851</td>\n",
       "      <td>0.570044</td>\n",
       "      <td>0.965945</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.026406</td>\n",
       "      <td>0.820891</td>\n",
       "      <td>0.464377</td>\n",
       "      <td>0.042581</td>\n",
       "      <td>0.018101</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.082545</td>\n",
       "      <td>0.026719</td>\n",
       "      <td>0.820963</td>\n",
       "      <td>0.466955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.114175</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.789745</td>\n",
       "      <td>0.842356</td>\n",
       "      <td>0.022761</td>\n",
       "      <td>0.037325</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.115544</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.856792</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.801665</td>\n",
       "      <td>0.861172</td>\n",
       "      <td>0.759212</td>\n",
       "      <td>0.936850</td>\n",
       "      <td>0.856600</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782487</td>\n",
       "      <td>0.977987</td>\n",
       "      <td>0.805364</td>\n",
       "      <td>0.109553</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>0.875187</td>\n",
       "      <td>0.882601</td>\n",
       "      <td>0.783212</td>\n",
       "      <td>0.979324</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.648372</td>\n",
       "      <td>0.855821</td>\n",
       "      <td>0.854678</td>\n",
       "      <td>0.980760</td>\n",
       "      <td>0.851452</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735934</td>\n",
       "      <td>0.989840</td>\n",
       "      <td>0.678614</td>\n",
       "      <td>0.108674</td>\n",
       "      <td>0.026260</td>\n",
       "      <td>0.600746</td>\n",
       "      <td>0.853251</td>\n",
       "      <td>0.736556</td>\n",
       "      <td>0.993189</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.189266</td>\n",
       "      <td>0.659848</td>\n",
       "      <td>0.932336</td>\n",
       "      <td>0.280091</td>\n",
       "      <td>0.057609</td>\n",
       "      <td>0.025285</td>\n",
       "      <td>0.313266</td>\n",
       "      <td>0.190342</td>\n",
       "      <td>0.660400</td>\n",
       "      <td>0.934648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068304</td>\n",
       "      <td>0.477987</td>\n",
       "      <td>0.224187</td>\n",
       "      <td>0.580744</td>\n",
       "      <td>0.910342</td>\n",
       "      <td>0.220709</td>\n",
       "      <td>0.113188</td>\n",
       "      <td>0.068536</td>\n",
       "      <td>0.477986</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   0.029108  0.813493  0.475749  0.038986  0.019014  0.006149  0.086889   \n",
       "1   0.034635  0.818138  0.496219  0.055261  0.019581  0.006241  0.093561   \n",
       "2   0.155122  0.697011  0.861830  0.226911  0.050652  0.020759  0.269356   \n",
       "3   0.073446  0.839473  0.677034  0.252271  0.021784  0.008316  0.157952   \n",
       "4   0.834316  0.000120  0.359754  0.445307  0.628219  0.478822  0.962452   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "75  0.915623  0.000000  0.000967  0.461014  0.962853  0.997525  0.998604   \n",
       "76  0.026406  0.820891  0.464377  0.042581  0.018101  0.005915  0.082545   \n",
       "77  0.856792  0.000964  0.003923  0.801665  0.861172  0.759212  0.936850   \n",
       "78  0.858757  0.000964  0.001990  0.648372  0.855821  0.854678  0.980760   \n",
       "79  0.189266  0.659848  0.932336  0.280091  0.057609  0.025285  0.313266   \n",
       "\n",
       "         7         8         9    ...       642       643       644       645  \\\n",
       "0   0.029660  0.813884  0.478888  ...  0.018380  0.136913  0.007596  0.776878   \n",
       "1   0.035298  0.818719  0.498778  ...  0.018099  0.136430  0.008070  0.801356   \n",
       "2   0.155534  0.697346  0.862477  ...  0.055422  0.422351  0.180275  0.621226   \n",
       "3   0.073906  0.840300  0.680059  ...  0.023076  0.270924  0.084026  0.824578   \n",
       "4   0.840422  0.000000  0.358982  ...  0.237660  0.769956  0.511156  0.159386   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "75  0.905503  0.000000  0.000625  ...  0.571394  0.965409  0.647164  0.000000   \n",
       "76  0.026719  0.820963  0.466955  ...  0.016775  0.114175  0.001305  0.789745   \n",
       "77  0.856600  0.000967  0.003921  ...  0.782487  0.977987  0.805364  0.109553   \n",
       "78  0.851452  0.000967  0.001989  ...  0.735934  0.989840  0.678614  0.108674   \n",
       "79  0.190342  0.660400  0.934648  ...  0.068304  0.477987  0.224187  0.580744   \n",
       "\n",
       "         646       647       648       649       650  651  \n",
       "0   0.857653  0.029664  0.039080  0.018702  0.137193  0.8  \n",
       "1   0.859352  0.042351  0.038282  0.018220  0.136463  0.8  \n",
       "2   0.930314  0.185821  0.096918  0.055665  0.419849  0.6  \n",
       "3   0.992351  0.190485  0.044535  0.023046  0.269764  0.8  \n",
       "4   0.537690  0.368470  0.354623  0.237300  0.768426  0.6  \n",
       "..       ...       ...       ...       ...       ...  ...  \n",
       "75  0.123608  0.376493  0.683851  0.570044  0.965945  0.8  \n",
       "76  0.842356  0.022761  0.037325  0.016973  0.115544  0.8  \n",
       "77  0.012110  0.875187  0.882601  0.783212  0.979324  0.6  \n",
       "78  0.026260  0.600746  0.853251  0.736556  0.993189  1.0  \n",
       "79  0.910342  0.220709  0.113188  0.068536  0.477986  0.6  \n",
       "\n",
       "[80 rows x 652 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_test_s = pd.DataFrame(scaler.fit_transform(X_test_1))\n",
    "X_test_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2dcdbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>642</th>\n",
       "      <th>643</th>\n",
       "      <th>644</th>\n",
       "      <th>645</th>\n",
       "      <th>646</th>\n",
       "      <th>647</th>\n",
       "      <th>648</th>\n",
       "      <th>649</th>\n",
       "      <th>650</th>\n",
       "      <th>651</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932939</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.852785</td>\n",
       "      <td>0.801356</td>\n",
       "      <td>0.709076</td>\n",
       "      <td>0.955173</td>\n",
       "      <td>0.933627</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706696</td>\n",
       "      <td>0.982792</td>\n",
       "      <td>0.817108</td>\n",
       "      <td>0.112773</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.911232</td>\n",
       "      <td>0.800911</td>\n",
       "      <td>0.707207</td>\n",
       "      <td>0.984645</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.170735</td>\n",
       "      <td>0.727291</td>\n",
       "      <td>0.887353</td>\n",
       "      <td>0.294824</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>0.281681</td>\n",
       "      <td>0.171411</td>\n",
       "      <td>0.727356</td>\n",
       "      <td>0.888681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041733</td>\n",
       "      <td>0.389481</td>\n",
       "      <td>0.167959</td>\n",
       "      <td>0.682776</td>\n",
       "      <td>0.925932</td>\n",
       "      <td>0.202018</td>\n",
       "      <td>0.077150</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>0.389471</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044540</td>\n",
       "      <td>0.869925</td>\n",
       "      <td>0.531774</td>\n",
       "      <td>0.117103</td>\n",
       "      <td>0.018266</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.108888</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>0.869527</td>\n",
       "      <td>0.533140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>0.177896</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>0.845587</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.091759</td>\n",
       "      <td>0.038768</td>\n",
       "      <td>0.019258</td>\n",
       "      <td>0.177187</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033342</td>\n",
       "      <td>0.864363</td>\n",
       "      <td>0.486829</td>\n",
       "      <td>0.072623</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.090740</td>\n",
       "      <td>0.033249</td>\n",
       "      <td>0.865028</td>\n",
       "      <td>0.489976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015105</td>\n",
       "      <td>0.132816</td>\n",
       "      <td>0.019910</td>\n",
       "      <td>0.834281</td>\n",
       "      <td>0.856943</td>\n",
       "      <td>0.046160</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0.133561</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.930387</td>\n",
       "      <td>0.263242</td>\n",
       "      <td>0.030309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.930174</td>\n",
       "      <td>0.265633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.112458</td>\n",
       "      <td>0.074083</td>\n",
       "      <td>0.828466</td>\n",
       "      <td>0.916198</td>\n",
       "      <td>0.022986</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.114550</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.780070</td>\n",
       "      <td>0.144554</td>\n",
       "      <td>0.721227</td>\n",
       "      <td>0.967526</td>\n",
       "      <td>0.288902</td>\n",
       "      <td>0.177449</td>\n",
       "      <td>0.797115</td>\n",
       "      <td>0.788413</td>\n",
       "      <td>0.143556</td>\n",
       "      <td>0.714318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513331</td>\n",
       "      <td>0.987882</td>\n",
       "      <td>0.879616</td>\n",
       "      <td>0.112773</td>\n",
       "      <td>0.080882</td>\n",
       "      <td>0.949355</td>\n",
       "      <td>0.583874</td>\n",
       "      <td>0.515276</td>\n",
       "      <td>0.989764</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.235908</td>\n",
       "      <td>0.620898</td>\n",
       "      <td>0.981225</td>\n",
       "      <td>0.273371</td>\n",
       "      <td>0.061054</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>0.365286</td>\n",
       "      <td>0.237154</td>\n",
       "      <td>0.620818</td>\n",
       "      <td>0.981257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097659</td>\n",
       "      <td>0.625788</td>\n",
       "      <td>0.323533</td>\n",
       "      <td>0.435328</td>\n",
       "      <td>0.791764</td>\n",
       "      <td>0.241450</td>\n",
       "      <td>0.146265</td>\n",
       "      <td>0.097891</td>\n",
       "      <td>0.626615</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.969552</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.984452</td>\n",
       "      <td>0.764437</td>\n",
       "      <td>0.737026</td>\n",
       "      <td>0.946177</td>\n",
       "      <td>0.974937</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786451</td>\n",
       "      <td>0.981823</td>\n",
       "      <td>0.836787</td>\n",
       "      <td>0.112773</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.982059</td>\n",
       "      <td>0.796493</td>\n",
       "      <td>0.787505</td>\n",
       "      <td>0.983670</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.866004</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>0.494588</td>\n",
       "      <td>0.580119</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.967272</td>\n",
       "      <td>0.867128</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.158062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222598</td>\n",
       "      <td>0.799806</td>\n",
       "      <td>0.527376</td>\n",
       "      <td>0.129926</td>\n",
       "      <td>0.483218</td>\n",
       "      <td>0.397122</td>\n",
       "      <td>0.345575</td>\n",
       "      <td>0.222320</td>\n",
       "      <td>0.797709</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.665702</td>\n",
       "      <td>0.226187</td>\n",
       "      <td>0.645560</td>\n",
       "      <td>0.230073</td>\n",
       "      <td>0.231871</td>\n",
       "      <td>0.121247</td>\n",
       "      <td>0.593765</td>\n",
       "      <td>0.668010</td>\n",
       "      <td>0.234438</td>\n",
       "      <td>0.639348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461245</td>\n",
       "      <td>0.696558</td>\n",
       "      <td>0.736428</td>\n",
       "      <td>0.218245</td>\n",
       "      <td>0.069666</td>\n",
       "      <td>0.434311</td>\n",
       "      <td>0.583598</td>\n",
       "      <td>0.462071</td>\n",
       "      <td>0.698270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   0.932939  0.000754  0.002617  0.852785  0.801356  0.709076  0.955173   \n",
       "1   0.170735  0.727291  0.887353  0.294824  0.046314  0.018252  0.281681   \n",
       "2   0.044540  0.869925  0.531774  0.117103  0.018266  0.006299  0.108888   \n",
       "3   0.033342  0.864363  0.486829  0.072623  0.016641  0.005302  0.090740   \n",
       "4   0.003649  0.930387  0.263242  0.030309  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "74  0.780070  0.144554  0.721227  0.967526  0.288902  0.177449  0.797115   \n",
       "75  0.235908  0.620898  0.981225  0.273371  0.061054  0.028380  0.365286   \n",
       "76  0.969552  0.000754  0.001309  0.984452  0.764437  0.737026  0.946177   \n",
       "77  0.866004  0.000251  0.159754  0.494588  0.580119  0.444900  0.967272   \n",
       "78  0.665702  0.226187  0.645560  0.230073  0.231871  0.121247  0.593765   \n",
       "\n",
       "         7         8         9    ...       642       643       644       645  \\\n",
       "0   0.933627  0.000756  0.002272  ...  0.706696  0.982792  0.817108  0.112773   \n",
       "1   0.171411  0.727356  0.888681  ...  0.041733  0.389481  0.167959  0.682776   \n",
       "2   0.044710  0.869527  0.533140  ...  0.019076  0.177896  0.039472  0.845587   \n",
       "3   0.033249  0.865028  0.489976  ...  0.015105  0.132816  0.019910  0.834281   \n",
       "4   0.003275  0.930174  0.265633  ...  0.006673  0.112458  0.074083  0.828466   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "74  0.788413  0.143556  0.714318  ...  0.513331  0.987882  0.879616  0.112773   \n",
       "75  0.237154  0.620818  0.981257  ...  0.097659  0.625788  0.323533  0.435328   \n",
       "76  0.974937  0.000756  0.001306  ...  0.786451  0.981823  0.836787  0.112773   \n",
       "77  0.867128  0.000252  0.158062  ...  0.222598  0.799806  0.527376  0.129926   \n",
       "78  0.668010  0.234438  0.639348  ...  0.461245  0.696558  0.736428  0.218245   \n",
       "\n",
       "         646       647       648       649       650  651  \n",
       "0   0.002920  0.911232  0.800911  0.707207  0.984645  0.6  \n",
       "1   0.925932  0.202018  0.077150  0.041814  0.389471  0.6  \n",
       "2   0.874296  0.091759  0.038768  0.019258  0.177187  0.8  \n",
       "3   0.856943  0.046160  0.032362  0.015309  0.133561  0.8  \n",
       "4   0.916198  0.022986  0.008753  0.007377  0.114550  0.6  \n",
       "..       ...       ...       ...       ...       ...  ...  \n",
       "74  0.080882  0.949355  0.583874  0.515276  0.989764  0.6  \n",
       "75  0.791764  0.241450  0.146265  0.097891  0.626615  0.6  \n",
       "76  0.000973  0.982059  0.796493  0.787505  0.983670  0.6  \n",
       "77  0.483218  0.397122  0.345575  0.222320  0.797709  0.6  \n",
       "78  0.069666  0.434311  0.583598  0.462071  0.698270  0.0  \n",
       "\n",
       "[79 rows x 652 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_val_s = pd.DataFrame(scaler.fit_transform(X_val_1))\n",
    "X_val_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e01ee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_nested is a nested DataFrame: True\n",
      "The cell contains a <class 'pandas.core.series.Series'>.\n",
      "The nested DataFrame has shape (80, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0      0.029108\n",
       "1      0.813493\n",
       "2      0.47574...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0      0.034635\n",
       "1      0.818138\n",
       "2      0.49621...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0      0.155122\n",
       "1      0.697011\n",
       "2      0.86183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0      0.073446\n",
       "1      0.839473\n",
       "2      0.67703...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0      0.834316\n",
       "1      0.000120\n",
       "2      0.35975...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  0      0.029108\n",
       "1      0.813493\n",
       "2      0.47574...\n",
       "1  0      0.034635\n",
       "1      0.818138\n",
       "2      0.49621...\n",
       "2  0      0.155122\n",
       "1      0.697011\n",
       "2      0.86183...\n",
       "3  0      0.073446\n",
       "1      0.839473\n",
       "2      0.67703...\n",
       "4  0      0.834316\n",
       "1      0.000120\n",
       "2      0.35975..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = from_2d_array_to_nested(X_test_s)\n",
    "print(f\"X_nested is a nested DataFrame: {is_nested_dataframe(X_test)}\")\n",
    "print(f\"The cell contains a {type(X_test.iloc[0,0])}.\")\n",
    "print(f\"The nested DataFrame has shape {X_test.shape}\")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66462f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_nested is a nested DataFrame: True\n",
      "The cell contains a <class 'pandas.core.series.Series'>.\n",
      "The nested DataFrame has shape (238, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0      0.097089\n",
       "1      0.888026\n",
       "2      0.40982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0      0.834456\n",
       "1      0.001447\n",
       "2      0.03834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0      0.846607\n",
       "1      0.001447\n",
       "2      0.00125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0      0.032964\n",
       "1      0.824803\n",
       "2      0.37073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0      0.137392\n",
       "1      0.833933\n",
       "2      0.52360...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  0      0.097089\n",
       "1      0.888026\n",
       "2      0.40982...\n",
       "1  0      0.834456\n",
       "1      0.001447\n",
       "2      0.03834...\n",
       "2  0      0.846607\n",
       "1      0.001447\n",
       "2      0.00125...\n",
       "3  0      0.032964\n",
       "1      0.824803\n",
       "2      0.37073...\n",
       "4  0      0.137392\n",
       "1      0.833933\n",
       "2      0.52360..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = from_2d_array_to_nested(X_train_s)\n",
    "print(f\"X_nested is a nested DataFrame: {is_nested_dataframe(X_train)}\")\n",
    "print(f\"The cell contains a {type(X_train.iloc[0,0])}.\")\n",
    "print(f\"The nested DataFrame has shape {X_train.shape}\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac6522f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_nested is a nested DataFrame: True\n",
      "The cell contains a <class 'pandas.core.series.Series'>.\n",
      "The nested DataFrame has shape (79, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0      0.932939\n",
       "1      0.000754\n",
       "2      0.00261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0      0.170735\n",
       "1      0.727291\n",
       "2      0.88735...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0      0.044540\n",
       "1      0.869925\n",
       "2      0.53177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0      0.033342\n",
       "1      0.864363\n",
       "2      0.48682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0      0.003649\n",
       "1      0.930387\n",
       "2      0.26324...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  0      0.932939\n",
       "1      0.000754\n",
       "2      0.00261...\n",
       "1  0      0.170735\n",
       "1      0.727291\n",
       "2      0.88735...\n",
       "2  0      0.044540\n",
       "1      0.869925\n",
       "2      0.53177...\n",
       "3  0      0.033342\n",
       "1      0.864363\n",
       "2      0.48682...\n",
       "4  0      0.003649\n",
       "1      0.930387\n",
       "2      0.26324..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = from_2d_array_to_nested(X_val_s)\n",
    "print(f\"X_nested is a nested DataFrame: {is_nested_dataframe(X_val)}\")\n",
    "print(f\"The cell contains a {type(X_val.iloc[0,0])}.\")\n",
    "print(f\"The nested DataFrame has shape {X_val.shape}\")\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aff5c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# import cupy as cp\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "print(type(X_train))\n",
    "print(len(X_test))\n",
    "\n",
    "models =  []\n",
    "models = create_models(models)\n",
    "\n",
    "def gpu(kf, models):\n",
    "    scoring = ['accuracy','precision_macro', 'recall_macro','f1_macro']\n",
    "    df_precision, df_accuracy, df_f1, df_recall, df_std = create_dt_metrics()\n",
    "#     with tf.device('/device:GPU:0'):\n",
    "    df_precision, df_accuracy, df_f1, df_recall, df_std = create_dt_metrics()\n",
    "    print(f\"Quantidade de modelos {len(models)}\")\n",
    "    for name, model in models:\n",
    "        print(f\"Treining {name}...\")\n",
    "        print(\"In trainning***\")\n",
    "#             with cp.cuda.Device(0):\n",
    "#                 cuda.to_device(X_train)\n",
    "#                 cuda.to_device(y_train)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"In prediction...\")\n",
    "        df_train = cross_validate(model, X_test, y_test, cv=kf, n_jobs=-1,scoring=scoring\n",
    "                                          ,return_train_score=True)\n",
    "        print(\"Finished prediction!\")\n",
    "        print(df_train.keys())\n",
    "        save_results(pd.DataFrame(df_train),name, model,'trainAndVal')\n",
    "        print(\"***********\")\n",
    "        print()\n",
    "#             df_validation = cross_validate(model, X_val, y_val, cv=kf, scoring=scoring)\n",
    "#             print(df_validation.keys())\n",
    "#             save_results(pd.DataFrame(df_validation), name, model,'test2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90105b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"Using MirroredStrategy\")\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "    else:  # Use the Default Strategy\n",
    "        print(\"Using Default Strategy\")\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    with strategy.scope():\n",
    "        # Do something interesting\n",
    "        print(tf.Variable(1.))\n",
    "        gpu(kf,models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1bcd115",
   "metadata": {},
   "source": [
    "### Executar só no final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_final_model(X_test, y_test, model):\n",
    "    scoring = ['accuracy','precision_macro', 'recall_macro','f1_macro']\n",
    "#     for name, model in models:\n",
    "        # df_test = cross_validate(model, X_test, y_test, cv=kf, scoring=scoring\n",
    "        #                          , return_train_score=True)\n",
    "#         print(f'Model in test: {name}')\n",
    "    df_test = pd.DataFrame([], columns=['accuracy','recall','precision','f1_score'])\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy  =  accuracy_score(y_test, y_pred)\n",
    "    recall    =  recall_score(y_test, y_pred, average='macro')\n",
    "    precision =  precision_score(y_test, y_pred, average='macro')\n",
    "    f1  =  f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"accuracy: {accuracy}, recall: {recall}, precision: {precision},f1: {f1} \")\n",
    "    df_test.at[0, 'accuracy'] = accuracy\n",
    "    df_test.at[0, 'recall'] = recall\n",
    "    df_test.at[0,'precision'] = precision\n",
    "    df_test.at[0,'f1_score'] = f1\n",
    "    print(df_test.keys())\n",
    "    save_results(df_test,\"HIVECOTE2\", model,'test')\n",
    "    print(\"Finished test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test, y_test = load_arff(\"AllCandidas_TEST_V3.arff\")\n",
    "print(len(X_val))\n",
    "# for name, model in models:\n",
    "test_final_model(X_val,y_val,loaded_model) #Executar isso só no final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cd4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_final_model(X_test, y_test, models):\n",
    "    scoring = ['accuracy','precision_macro', 'recall_macro','f1_macro']\n",
    "    for name, model in models:\n",
    "        df_test = cross_validate(model, X_test, y_test, cv=kf, scoring=scoring\n",
    "                                 , return_train_score=True)\n",
    "        print(df_test.keys())\n",
    "        save_results(pd.DataFrame(df_test),name, model,'test')\n",
    "        print(\"Finished test!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
